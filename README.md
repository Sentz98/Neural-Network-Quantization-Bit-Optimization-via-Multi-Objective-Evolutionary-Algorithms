# Neural Network Quantization Bit Optimization via Multi-Objective Evolutionary Algorithms

Advancements in neural network technology are
often driven by increasing model size, enhancing capabilities
but also escalating computational demands. Neural network
quantization, particularly reducing the precision of weights and
activations, is a crucial technique to mitigate these demands.
While effective in reducing memory footprint and computational
load, quantization introduces noise, potentially degrading accu-
racy. This study explores optimizing bit-width assignment across
neural networks using multi-objective evolutionary algorithms,
evaluating both layer-wise and neuron-wise approaches. The
Non-dominated Sorting Genetic Algorithm II (NSGA-II) was
employed to balance model size and accuracy trade-offs, demon-
strating significant efficiency in handling complex optimization
landscapes.
